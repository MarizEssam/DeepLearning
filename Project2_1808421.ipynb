{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mariz Essam Sobhy Ghaly\n",
        "#1808421"
      ],
      "metadata": {
        "id": "zUD1SE5cagBU"
      },
      "id": "zUD1SE5cagBU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTly760raXeB"
      },
      "source": [
        "In \\[1\\]:\n",
        "\n",
        "    import os\n",
        "    import random\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "    import tensorflow as tf\n",
        "    from keras.utils.vis_utils import plot_model\n",
        "    from keras.utils.np_utils import to_categorical\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Conv2D, AveragePooling2D, Dense, Flatten\n",
        "    from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "\n",
        "    BATCH_SIZE = 4096\n",
        "\n",
        "In \\[2\\]:\n",
        "\n",
        "    seed = 42\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)                    \n",
        "    random.seed(seed)\n",
        "\n",
        "# Reading Data and pre-processing<a href=\"#Reading-Data-and-pre-processing\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[3\\]:\n",
        "\n",
        "    train = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\n",
        "    test = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\n",
        "\n",
        "In \\[4\\]:\n",
        "\n",
        "    train.describe()\n",
        "\n",
        "Out\\[4\\]:\n",
        "\n",
        "|       | label        | pixel1       | pixel2       | pixel3       | pixel4       | pixel5       | pixel6       | pixel7       | pixel8       | pixel9       | ... | pixel775     | pixel776     | pixel777     | pixel778     | pixel779     | pixel780     | pixel781     | pixel782     | pixel783     | pixel784    |\n",
        "|-------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|-----|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|-------------|\n",
        "| count | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | ... | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.000000 | 60000.00000 |\n",
        "| mean  | 4.500000     | 0.000900     | 0.006150     | 0.035333     | 0.101933     | 0.247967     | 0.411467     | 0.805767     | 2.198283     | 5.682000     | ... | 34.625400    | 23.300683    | 16.588267    | 17.869433    | 22.814817    | 17.911483    | 8.520633     | 2.753300     | 0.855517     | 0.07025     |\n",
        "| std   | 2.872305     | 0.094689     | 0.271011     | 1.222324     | 2.452871     | 4.306912     | 5.836188     | 8.215169     | 14.093378    | 23.819481    | ... | 57.545242    | 48.854427    | 41.979611    | 43.966032    | 51.830477    | 45.149388    | 29.614859    | 17.397652    | 9.356960     | 2.12587     |\n",
        "| min   | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | ... | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.00000     |\n",
        "| 25%   | 2.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | ... | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.00000     |\n",
        "| 50%   | 4.500000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | ... | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.00000     |\n",
        "| 75%   | 7.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | ... | 58.000000    | 9.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.000000     | 0.00000     |\n",
        "| max   | 9.000000     | 16.000000    | 36.000000    | 226.000000   | 164.000000   | 227.000000   | 230.000000   | 224.000000   | 255.000000   | 254.000000   | ... | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 255.000000   | 170.00000   |\n",
        "\n",
        "8 rows × 785 columns\n",
        "\n",
        "In \\[5\\]:\n",
        "\n",
        "    train['label'].describe()\n",
        "\n",
        "Out\\[5\\]:\n",
        "\n",
        "    count    60000.000000\n",
        "    mean         4.500000\n",
        "    std          2.872305\n",
        "    min          0.000000\n",
        "    25%          2.000000\n",
        "    50%          4.500000\n",
        "    75%          7.000000\n",
        "    max          9.000000\n",
        "    Name: label, dtype: float64\n",
        "\n",
        "## Labels Freq. Analysis<a href=\"#Labels-Freq.-Analysis\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[6\\]:\n",
        "\n",
        "    def num_to_cloth(argument):\n",
        "        switcher = {\n",
        "            0: \"T-shirt/top\",\n",
        "            1: \"Trouser\",\n",
        "            2: \"Pullover\",\n",
        "            3: \"Dress\",\n",
        "            4: \"Coat\",\n",
        "            5: \"Sandal\",\n",
        "            6: \"Shirt\",\n",
        "            7: \"Sneaker\",\n",
        "            8: \"Bag\",\n",
        "            9: \"Ankle boot\"\n",
        "        }\n",
        "        return switcher.get(argument, \"nothing\")\n",
        "\n",
        "In \\[7\\]:\n",
        "\n",
        "    elements_count = {}\n",
        "    for element in train[\"label\"]:\n",
        "       if element in elements_count:\n",
        "          elements_count[element] += 1\n",
        "       else:\n",
        "          elements_count[element] = 1\n",
        "    print(type(elements_count))\n",
        "    for key, value in sorted(elements_count.items()):\n",
        "       print(f\"{key}: {value} => {num_to_cloth(key)}\")\n",
        "\n",
        "    print(\"\\nWe have {} cloth types and each one repeated exactly 6000 times\".format(len(elements_count)))\n",
        "\n",
        "    <class 'dict'>\n",
        "    0: 6000 => T-shirt/top\n",
        "    1: 6000 => Trouser\n",
        "    2: 6000 => Pullover\n",
        "    3: 6000 => Dress\n",
        "    4: 6000 => Coat\n",
        "    5: 6000 => Sandal\n",
        "    6: 6000 => Shirt\n",
        "    7: 6000 => Sneaker\n",
        "    8: 6000 => Bag\n",
        "    9: 6000 => Ankle boot\n",
        "\n",
        "    We have 10 cloth types and each one repeated exactly 6000 times\n",
        "\n",
        "In \\[9\\]:\n",
        "\n",
        "    train.label.value_counts()\n",
        "\n",
        "Out\\[9\\]:\n",
        "\n",
        "    2    6000\n",
        "    9    6000\n",
        "    6    6000\n",
        "    0    6000\n",
        "    3    6000\n",
        "    4    6000\n",
        "    5    6000\n",
        "    8    6000\n",
        "    7    6000\n",
        "    1    6000\n",
        "    Name: label, dtype: int64\n",
        "\n",
        "In \\[10\\]:\n",
        "\n",
        "    train.head()\n",
        "\n",
        "Out\\[10\\]:\n",
        "\n",
        "|     | label | pixel1 | pixel2 | pixel3 | pixel4 | pixel5 | pixel6 | pixel7 | pixel8 | pixel9 | ... | pixel775 | pixel776 | pixel777 | pixel778 | pixel779 | pixel780 | pixel781 | pixel782 | pixel783 | pixel784 |\n",
        "|-----|-------|--------|--------|--------|--------|--------|--------|--------|--------|--------|-----|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
        "| 0   | 2     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "| 1   | 9     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "| 2   | 6     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 5      | 0      | ... | 0        | 0        | 0        | 30       | 43       | 0        | 0        | 0        | 0        | 0        |\n",
        "| 3   | 0     | 0      | 0      | 0      | 1      | 2      | 0      | 0      | 0      | 0      | ... | 3        | 0        | 0        | 0        | 0        | 1        | 0        | 0        | 0        | 0        |\n",
        "| 4   | 3     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "\n",
        "5 rows × 785 columns\n",
        "\n",
        "In \\[11\\]:\n",
        "\n",
        "    test.head()\n",
        "\n",
        "Out\\[11\\]:\n",
        "\n",
        "|     | label | pixel1 | pixel2 | pixel3 | pixel4 | pixel5 | pixel6 | pixel7 | pixel8 | pixel9 | ... | pixel775 | pixel776 | pixel777 | pixel778 | pixel779 | pixel780 | pixel781 | pixel782 | pixel783 | pixel784 |\n",
        "|-----|-------|--------|--------|--------|--------|--------|--------|--------|--------|--------|-----|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
        "| 0   | 0     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 9      | 8      | ... | 103      | 87       | 56       | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "| 1   | 1     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 34       | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "| 2   | 2     | 0      | 0      | 0      | 0      | 0      | 0      | 14     | 53     | 99     | ... | 0        | 0        | 0        | 0        | 63       | 53       | 31       | 0        | 0        | 0        |\n",
        "| 3   | 2     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 137      | 126      | 140      | 0        | 133      | 224      | 222      | 56       | 0        | 0        |\n",
        "| 4   | 3     | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | ... | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        | 0        |\n",
        "\n",
        "5 rows × 785 columns\n",
        "\n",
        "In \\[13\\]:\n",
        "\n",
        "    print(train.shape)\n",
        "    print(test.shape)\n",
        "\n",
        "    (60000, 785)\n",
        "    (10000, 785)\n",
        "\n",
        "In \\[14\\]:\n",
        "\n",
        "    print(f\"Training observations {train.shape[0]}, Test observations {test.shape[0]} \\n\")\n",
        "\n",
        "    Training observations 60000, Test observations 10000 \n",
        "\n",
        "## Cleaning the data from NULL or Duplicates<a href=\"#Cleaning-the-data-from-NULL-or-Duplicates\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[15\\]:\n",
        "\n",
        "    #If the output is zero, it means that there are no missing values in our dataset.\n",
        "    print(train.isnull().sum().sum())\n",
        "\n",
        "    0\n",
        "\n",
        "In \\[16\\]:\n",
        "\n",
        "    # dropping duplicates by considering all rows\n",
        "    count = 0\n",
        "    for element in train.duplicated():\n",
        "        count = count + 1 if (element == True) else count\n",
        "    print(\"number of duplicate elements is\", count)\n",
        "\n",
        "    number of duplicate elements is 43\n",
        "\n",
        "In \\[21\\]:\n",
        "\n",
        "    # dropping duplicates by considering all columns other than ID & Species\n",
        "    pixels = list(train.columns)[1:]\n",
        "    print(train.shape)\n",
        "    train.drop_duplicates(subset=pixels, inplace=True)\n",
        "    print(train.shape)\n",
        "\n",
        "    (60000, 785)\n",
        "    (59957, 785)\n",
        "\n",
        "### Conclusion: The Data contains no missing values but contains 43 duplicate element<a href=\"#Conclusion:-The-Data-contains-no-missing-values-but-contains-43-duplicate-element\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "## Visualizing some of the images<a href=\"#Visualizing-some-of-the-images\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[22\\]:\n",
        "\n",
        "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    plt.figure(figsize=(12,9))\n",
        "    for i in range(0,12):\n",
        "        plt.subplot(3,4,i+1)\n",
        "        image_resized = np.resize(train.iloc[i,1:].values,(28,28))\n",
        "        plt.title(class_names[train.iloc[i,0]])\n",
        "        plt.imshow(image_resized, cmap='gray', interpolation='none')\n",
        "        plt.axis('off')\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/031ac33eedbd4d17fe607093fe2135bfbf0f7977.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "### Extracting Features and Labels from the data<a href=\"#Extracting-Features-and-Labels-from-the-data\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[23\\]:\n",
        "\n",
        "    X_train = np.array(train.iloc[:, 1:])\n",
        "    y_train = to_categorical(np.array(train.iloc[:, 0]))\n",
        "\n",
        "In \\[24\\]:\n",
        "\n",
        "    y_train\n",
        "\n",
        "Out\\[24\\]:\n",
        "\n",
        "    array([[0., 0., 1., ..., 0., 0., 0.],\n",
        "           [0., 0., 0., ..., 0., 0., 1.],\n",
        "           [0., 0., 0., ..., 0., 0., 0.],\n",
        "           ...,\n",
        "           [0., 0., 0., ..., 0., 1., 0.],\n",
        "           [0., 0., 0., ..., 0., 1., 0.],\n",
        "           [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)\n",
        "\n",
        "In \\[25\\]:\n",
        "\n",
        "    X_test = np.array(test.iloc[:, 1:])\n",
        "    y_test = to_categorical(np.array(test.iloc[:, 0]))\n",
        "\n",
        "In \\[26\\]:\n",
        "\n",
        "    y_test\n",
        "\n",
        "Out\\[26\\]:\n",
        "\n",
        "    array([[1., 0., 0., ..., 0., 0., 0.],\n",
        "           [0., 1., 0., ..., 0., 0., 0.],\n",
        "           [0., 0., 1., ..., 0., 0., 0.],\n",
        "           ...,\n",
        "           [0., 0., 0., ..., 0., 1., 0.],\n",
        "           [0., 0., 0., ..., 0., 1., 0.],\n",
        "           [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)\n",
        "\n",
        "## Correlation Analysis<a href=\"#Correlation-Analysis\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[31\\]:\n",
        "\n",
        "    corr_matrix = train.corr().abs()\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
        "    upper_tri.head()\n",
        "\n",
        "    /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
        "    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
        "      \n",
        "\n",
        "Out\\[31\\]:\n",
        "\n",
        "|        | label | pixel1   | pixel2   | pixel3   | pixel4   | pixel5   | pixel6   | pixel7   | pixel8   | pixel9   | ... | pixel775 | pixel776 | pixel777 | pixel778 | pixel779 | pixel780 | pixel781 | pixel782 | pixel783 | pixel784 |\n",
        "|--------|-------|----------|----------|----------|----------|----------|----------|----------|----------|----------|-----|----------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n",
        "| label  | NaN   | 0.000676 | 0.002942 | 0.010453 | 0.007119 | 0.004629 | 0.011058 | 0.036828 | 0.085385 | 0.161761 | ... | 0.362817 | 0.258533 | 0.183235 | 0.090386 | 0.077161 | 0.066846 | 0.018054 | 0.045588 | 0.059963 | 0.021773 |\n",
        "| pixel1 | NaN   | NaN      | 0.297899 | 0.067551 | 0.046607 | 0.026630 | 0.026172 | 0.012096 | 0.012225 | 0.009644 | ... | 0.000641 | 0.004628 | 0.004609 | 0.000975 | 0.002305 | 0.002442 | 0.000109 | 0.008764 | 0.026388 | 0.041581 |\n",
        "| pixel2 | NaN   | NaN      | NaN      | 0.575033 | 0.138709 | 0.054353 | 0.033184 | 0.022766 | 0.017138 | 0.016821 | ... | 0.000494 | 0.004861 | 0.006817 | 0.002097 | 0.004427 | 0.002341 | 0.004271 | 0.014215 | 0.021296 | 0.022161 |\n",
        "| pixel3 | NaN   | NaN      | NaN      | NaN      | 0.387468 | 0.118136 | 0.087300 | 0.060937 | 0.035942 | 0.029674 | ... | 0.010095 | 0.016706 | 0.018323 | 0.006163 | 0.003821 | 0.001494 | 0.006861 | 0.013151 | 0.009946 | 0.015657 |\n",
        "| pixel4 | NaN   | NaN      | NaN      | NaN      | NaN      | 0.573172 | 0.325683 | 0.242987 | 0.141033 | 0.085302 | ... | 0.009690 | 0.018710 | 0.023391 | 0.016759 | 0.009700 | 0.010101 | 0.023940 | 0.012388 | 0.003072 | 0.008422 |\n",
        "\n",
        "5 rows × 785 columns\n",
        "\n",
        "In \\[32\\]:\n",
        "\n",
        "    im_rows, im_cols = 28, 28\n",
        "    input_shape = (im_rows, im_cols, 1)\n",
        "\n",
        "    # train and validate sets\n",
        "    X_train = X_train.reshape(X_train.shape[0], im_rows, im_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], im_rows, im_cols, 1)\n",
        "\n",
        "    # normalisation\n",
        "    X_train = X_train/255\n",
        "    X_test = X_test/255\n",
        "\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "    X_train shape: (59957, 28, 28, 1)\n",
        "    X_test shape: (10000, 28, 28, 1)\n",
        "    y_train shape: (59957, 10)\n",
        "    y_test shape: (10000, 10)\n",
        "\n",
        "In \\[33\\]:\n",
        "\n",
        "    def lenet5(input_sh, opt=tf.keras.optimizers.Adam(learning_rate=0.001)):\n",
        "        \n",
        "        model = Sequential(\n",
        "            [\n",
        "                Conv2D(filters = 6, kernel_size = (5, 5), strides = (1, 1), activation = \"tanh\", input_shape = input_sh),\n",
        "                AveragePooling2D(pool_size = (2, 2)),\n",
        "                Conv2D(filters = 16, kernel_size = (5, 5), strides = (1, 1), activation = \"tanh\"),\n",
        "                AveragePooling2D(pool_size = (2, 2), strides = 2),\n",
        "                \n",
        "                Flatten(),\n",
        "                Dense(units = 120, activation = \"tanh\"),\n",
        "                Dense(units = 84, activation = \"tanh\"),\n",
        "                Dense(units = 10, activation = \"softmax\")\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        model.compile(optimizer=opt,\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "        model.summary()\n",
        "        \n",
        "        return model\n",
        "\n",
        "In \\[46\\]:\n",
        "\n",
        "    model_1 = lenet5(input_shape, tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "\n",
        "    Model: \"sequential_2\"\n",
        "    _________________________________________________________________\n",
        "    Layer (type)                 Output Shape              Param #   \n",
        "    =================================================================\n",
        "    conv2d_4 (Conv2D)            (None, 24, 24, 6)         156       \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_4 (Average (None, 12, 12, 6)         0         \n",
        "    _________________________________________________________________\n",
        "    conv2d_5 (Conv2D)            (None, 8, 8, 16)          2416      \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_5 (Average (None, 4, 4, 16)          0         \n",
        "    _________________________________________________________________\n",
        "    flatten_2 (Flatten)          (None, 256)               0         \n",
        "    _________________________________________________________________\n",
        "    dense_6 (Dense)              (None, 120)               30840     \n",
        "    _________________________________________________________________\n",
        "    dense_7 (Dense)              (None, 84)                10164     \n",
        "    _________________________________________________________________\n",
        "    dense_8 (Dense)              (None, 10)                850       \n",
        "    =================================================================\n",
        "    Total params: 44,426\n",
        "    Trainable params: 44,426\n",
        "    Non-trainable params: 0\n",
        "    _________________________________________________________________\n",
        "\n",
        "In \\[47\\]:\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    k = 5\n",
        "    cross_val = KFold(k, shuffle=True, random_state=1)\n",
        "    fold_count = 1\n",
        "\n",
        "    # For training epochs\n",
        "    epochs = 32\n",
        "\n",
        "    # For loss & acc plotting\n",
        "    histories = []\n",
        "\n",
        "    # For testing/evaluation acc scores\n",
        "    eval_scores = []\n",
        "\n",
        "    # For callbacks\n",
        "    es_callbacks = EarlyStopping(monitor=\"val_loss\",\n",
        "                                              mode=\"min\",\n",
        "                                              verbose=1,\n",
        "                                              patience=4)\n",
        "\n",
        "In \\[48\\]:\n",
        "\n",
        "    for train, validation in cross_val.split(X_train):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Fold-{}\".format(fold_count))\n",
        "        print(\"-\"*80)\n",
        "        print(\"Training & Validation\")\n",
        "        fold_count = fold_count + 1\n",
        "        \n",
        "        \n",
        "        X_train_, y_train_ = X_train[train], y_train[train]\n",
        "        X_val, y_val = X_train[validation], y_train[validation]\n",
        "        \n",
        "        history = model_1.fit(X_train_, y_train_,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[es_callbacks])\n",
        "        \n",
        "        print(\"-\"*80)\n",
        "        print(\"Testing/evaluation\")\n",
        "        eval_loss, eval_accuracy = model_1.evaluate(X_test, y_test)\n",
        "        \n",
        "        histories.append(history)\n",
        "        eval_scores.append(eval_accuracy)\n",
        "        print(\"_\"*80)\n",
        "\n",
        "    ================================================================================\n",
        "    Fold-1\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 12s 8ms/step - loss: 0.5897 - accuracy: 0.7810 - val_loss: 0.4856 - val_accuracy: 0.8256\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.4231 - accuracy: 0.8456 - val_loss: 0.4166 - val_accuracy: 0.8491\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.3750 - accuracy: 0.8621 - val_loss: 0.3945 - val_accuracy: 0.8567\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 12s 8ms/step - loss: 0.3428 - accuracy: 0.8728 - val_loss: 0.3748 - val_accuracy: 0.8633\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.3223 - accuracy: 0.8820 - val_loss: 0.3597 - val_accuracy: 0.8726\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.3039 - accuracy: 0.8884 - val_loss: 0.3497 - val_accuracy: 0.8729\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2858 - accuracy: 0.8942 - val_loss: 0.3586 - val_accuracy: 0.8694\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2715 - accuracy: 0.8989 - val_loss: 0.3334 - val_accuracy: 0.8815\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2578 - accuracy: 0.9038 - val_loss: 0.3227 - val_accuracy: 0.8846\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2448 - accuracy: 0.9092 - val_loss: 0.3269 - val_accuracy: 0.8833\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2334 - accuracy: 0.9132 - val_loss: 0.3248 - val_accuracy: 0.8853\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 12s 8ms/step - loss: 0.2224 - accuracy: 0.9162 - val_loss: 0.3287 - val_accuracy: 0.8839\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 11s 8ms/step - loss: 0.2102 - accuracy: 0.9210 - val_loss: 0.3407 - val_accuracy: 0.8826\n",
        "    Epoch 00013: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3217 - accuracy: 0.8824\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-2\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2386 - accuracy: 0.9124 - val_loss: 0.2157 - val_accuracy: 0.9170\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 12s 8ms/step - loss: 0.2200 - accuracy: 0.9196 - val_loss: 0.2195 - val_accuracy: 0.9185\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2074 - accuracy: 0.9247 - val_loss: 0.2193 - val_accuracy: 0.9177\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1979 - accuracy: 0.9279 - val_loss: 0.2237 - val_accuracy: 0.9161\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1872 - accuracy: 0.9318 - val_loss: 0.2295 - val_accuracy: 0.9133\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.8920\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-3\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1975 - accuracy: 0.9274 - val_loss: 0.1803 - val_accuracy: 0.9326\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1823 - accuracy: 0.9324 - val_loss: 0.1838 - val_accuracy: 0.9309\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 11s 8ms/step - loss: 0.1731 - accuracy: 0.9370 - val_loss: 0.1816 - val_accuracy: 0.9323\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1621 - accuracy: 0.9414 - val_loss: 0.1873 - val_accuracy: 0.9311\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1547 - accuracy: 0.9427 - val_loss: 0.1982 - val_accuracy: 0.9267\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 2s 5ms/step - loss: 0.3296 - accuracy: 0.8913\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-4\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1683 - accuracy: 0.9392 - val_loss: 0.1413 - val_accuracy: 0.9476\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1559 - accuracy: 0.9429 - val_loss: 0.1626 - val_accuracy: 0.9380\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 12s 8ms/step - loss: 0.1447 - accuracy: 0.9480 - val_loss: 0.1504 - val_accuracy: 0.9448\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1353 - accuracy: 0.9517 - val_loss: 0.1671 - val_accuracy: 0.9351\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1307 - accuracy: 0.9527 - val_loss: 0.1730 - val_accuracy: 0.9336\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8874\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-5\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 8ms/step - loss: 0.1422 - accuracy: 0.9476 - val_loss: 0.1266 - val_accuracy: 0.9543\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1267 - accuracy: 0.9539 - val_loss: 0.1248 - val_accuracy: 0.9541\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1192 - accuracy: 0.9571 - val_loss: 0.1396 - val_accuracy: 0.9464\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 11s 8ms/step - loss: 0.1121 - accuracy: 0.9593 - val_loss: 0.1396 - val_accuracy: 0.9490\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1059 - accuracy: 0.9624 - val_loss: 0.1447 - val_accuracy: 0.9474\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.0981 - accuracy: 0.9658 - val_loss: 0.1693 - val_accuracy: 0.9367\n",
        "    Epoch 00006: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8865\n",
        "    ________________________________________________________________________________\n",
        "\n",
        "In \\[49\\]:\n",
        "\n",
        "    def display_kfold_result(history, k=1):\n",
        "        # Train & Val Loss\n",
        "        loss = history.history[\"loss\"]\n",
        "        val_loss = history.history[\"val_loss\"]\n",
        "        \n",
        "        # Train & Val Accuracy\n",
        "        accuracy = history.history[\"accuracy\"]\n",
        "        val_accuracy = history.history[\"val_accuracy\"]\n",
        "        \n",
        "        plt.figure(figsize=(15, 5))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(loss, label=\"Training\")\n",
        "        plt.plot(val_loss, label=\"Validation\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(accuracy, label=\"Training\")\n",
        "        plt.plot(val_accuracy, label=\"Validation\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        \n",
        "        plt.suptitle(\"Fold-{}\".format(k))\n",
        "        plt.show()\n",
        "\n",
        "In \\[50\\]:\n",
        "\n",
        "    # Displaying the graph results\n",
        "\n",
        "    for history in histories:\n",
        "        display_kfold_result(history, (histories.index(history)+1))\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/a66009d4bdfc2c19c820b94801b2a9f6e9f4bc10.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/5b001e9e2bddb9f4b1fe168e9a44f7b6a944dc3a.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/129ffe2ee9734bf3a66fcaab0076277467b54e78.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/ca986c63315a3671d1cc9697d9456f946641a149.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/f3b9fce0994a26e279f930bd15dd8c1bad753478.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "In \\[51\\]:\n",
        "\n",
        "    i = 0\n",
        "    float2 = \"{0:.2f}\"\n",
        "    for score in eval_scores:\n",
        "        percent = score * 100\n",
        "        print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n",
        "        i = i + 1\n",
        "\n",
        "    Fold-1: 88.24%\n",
        "    Fold-2: 89.20%\n",
        "    Fold-3: 89.13%\n",
        "    Fold-4: 88.74%\n",
        "    Fold-5: 88.65%\n",
        "\n",
        "## Trying RMSProp Optimizer<a href=\"#Trying-RMSProp-Optimizer\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[58\\]:\n",
        "\n",
        "    model_2 = lenet5(input_shape, tf.keras.optimizers.RMSprop(learning_rate=0.001))\n",
        "\n",
        "    Model: \"sequential_4\"\n",
        "    _________________________________________________________________\n",
        "    Layer (type)                 Output Shape              Param #   \n",
        "    =================================================================\n",
        "    conv2d_8 (Conv2D)            (None, 24, 24, 6)         156       \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_8 (Average (None, 12, 12, 6)         0         \n",
        "    _________________________________________________________________\n",
        "    conv2d_9 (Conv2D)            (None, 8, 8, 16)          2416      \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_9 (Average (None, 4, 4, 16)          0         \n",
        "    _________________________________________________________________\n",
        "    flatten_4 (Flatten)          (None, 256)               0         \n",
        "    _________________________________________________________________\n",
        "    dense_12 (Dense)             (None, 120)               30840     \n",
        "    _________________________________________________________________\n",
        "    dense_13 (Dense)             (None, 84)                10164     \n",
        "    _________________________________________________________________\n",
        "    dense_14 (Dense)             (None, 10)                850       \n",
        "    =================================================================\n",
        "    Total params: 44,426\n",
        "    Trainable params: 44,426\n",
        "    Non-trainable params: 0\n",
        "    _________________________________________________________________\n",
        "\n",
        "In \\[59\\]:\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    k = 5\n",
        "    cross_val = KFold(k, shuffle=True, random_state=1)\n",
        "    fold_count = 1\n",
        "\n",
        "    # For training epochs\n",
        "    epochs = 32\n",
        "\n",
        "    # For loss & acc plotting\n",
        "    histories = []\n",
        "\n",
        "    # For testing/evaluation acc scores\n",
        "    eval_scores = []\n",
        "\n",
        "    # For callbacks\n",
        "    es_callbacks = EarlyStopping(monitor=\"val_loss\",\n",
        "                                              mode=\"min\",\n",
        "                                              verbose=1,\n",
        "                                              patience=4)\n",
        "\n",
        "In \\[60\\]:\n",
        "\n",
        "    for train, validation in cross_val.split(X_train):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Fold-{}\".format(fold_count))\n",
        "        print(\"-\"*80)\n",
        "        print(\"Training & Validation\")\n",
        "        fold_count = fold_count + 1\n",
        "        \n",
        "        \n",
        "        X_train_, y_train_ = X_train[train], y_train[train]\n",
        "        X_val, y_val = X_train[validation], y_train[validation]\n",
        "        \n",
        "        history = model_2.fit(X_train_, y_train_,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[es_callbacks])\n",
        "        \n",
        "        print(\"-\"*80)\n",
        "        print(\"Testing/evaluation\")\n",
        "        eval_loss, eval_accuracy = model_2.evaluate(X_test, y_test)\n",
        "        \n",
        "        histories.append(history)\n",
        "        eval_scores.append(eval_accuracy)\n",
        "        print(\"_\"*80)\n",
        "\n",
        "    ================================================================================\n",
        "    Fold-1\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.5779 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.8113\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4146 - accuracy: 0.8463 - val_loss: 0.4108 - val_accuracy: 0.8567\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3677 - accuracy: 0.8647 - val_loss: 0.3741 - val_accuracy: 0.8655\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3381 - accuracy: 0.8768 - val_loss: 0.3776 - val_accuracy: 0.8661\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.3176 - accuracy: 0.8830 - val_loss: 0.3453 - val_accuracy: 0.8777\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2974 - accuracy: 0.8904 - val_loss: 0.3346 - val_accuracy: 0.8805\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2823 - accuracy: 0.8951 - val_loss: 0.3381 - val_accuracy: 0.8755\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2678 - accuracy: 0.9001 - val_loss: 0.3313 - val_accuracy: 0.8863\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.2562 - accuracy: 0.9036 - val_loss: 0.3167 - val_accuracy: 0.8863\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2449 - accuracy: 0.9088 - val_loss: 0.3228 - val_accuracy: 0.8862\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2365 - accuracy: 0.9116 - val_loss: 0.3152 - val_accuracy: 0.8892\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2259 - accuracy: 0.9166 - val_loss: 0.3393 - val_accuracy: 0.8839\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2162 - accuracy: 0.9200 - val_loss: 0.3115 - val_accuracy: 0.8916\n",
        "    Epoch 14/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2067 - accuracy: 0.9239 - val_loss: 0.3176 - val_accuracy: 0.8924\n",
        "    Epoch 15/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1993 - accuracy: 0.9262 - val_loss: 0.3212 - val_accuracy: 0.8898\n",
        "    Epoch 16/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1919 - accuracy: 0.9286 - val_loss: 0.3269 - val_accuracy: 0.8879\n",
        "    Epoch 17/32\n",
        "    1499/1499 [==============================] - 11s 8ms/step - loss: 0.1842 - accuracy: 0.9322 - val_loss: 0.3182 - val_accuracy: 0.8928\n",
        "    Epoch 00017: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.8925\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-2\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.2171 - accuracy: 0.9206 - val_loss: 0.1968 - val_accuracy: 0.9263\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.2020 - accuracy: 0.9260 - val_loss: 0.1981 - val_accuracy: 0.9280\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1906 - accuracy: 0.9305 - val_loss: 0.2011 - val_accuracy: 0.9241\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.2089 - val_accuracy: 0.9243\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1734 - accuracy: 0.9368 - val_loss: 0.2149 - val_accuracy: 0.9234\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8957\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-3\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1841 - accuracy: 0.9331 - val_loss: 0.1499 - val_accuracy: 0.9430\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.1717 - accuracy: 0.9377 - val_loss: 0.1705 - val_accuracy: 0.9353\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1647 - accuracy: 0.9401 - val_loss: 0.1661 - val_accuracy: 0.9379\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1564 - accuracy: 0.9433 - val_loss: 0.1735 - val_accuracy: 0.9347\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.1475 - accuracy: 0.9468 - val_loss: 0.1861 - val_accuracy: 0.9304\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8891\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-4\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1590 - accuracy: 0.9420 - val_loss: 0.1248 - val_accuracy: 0.9556\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1489 - accuracy: 0.9448 - val_loss: 0.1531 - val_accuracy: 0.9426\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1408 - accuracy: 0.9495 - val_loss: 0.1490 - val_accuracy: 0.9430\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1331 - accuracy: 0.9532 - val_loss: 0.1632 - val_accuracy: 0.9380\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1268 - accuracy: 0.9547 - val_loss: 0.1690 - val_accuracy: 0.9383\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.8905\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-5\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.1149 - val_accuracy: 0.9577\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.1267 - accuracy: 0.9543 - val_loss: 0.1272 - val_accuracy: 0.9531\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1198 - accuracy: 0.9563 - val_loss: 0.1278 - val_accuracy: 0.9523\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.1140 - accuracy: 0.9589 - val_loss: 0.1448 - val_accuracy: 0.9483\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.1071 - accuracy: 0.9609 - val_loss: 0.1462 - val_accuracy: 0.9479\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3914 - accuracy: 0.8864\n",
        "    ________________________________________________________________________________\n",
        "\n",
        "In \\[55\\]:\n",
        "\n",
        "    def display_kfold_result(history, k=1):\n",
        "        # Train & Val Loss\n",
        "        loss = history.history[\"loss\"]\n",
        "        val_loss = history.history[\"val_loss\"]\n",
        "        \n",
        "        # Train & Val Accuracy\n",
        "        accuracy = history.history[\"accuracy\"]\n",
        "        val_accuracy = history.history[\"val_accuracy\"]\n",
        "        \n",
        "        plt.figure(figsize=(15, 5))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(loss, label=\"Training\")\n",
        "        plt.plot(val_loss, label=\"Validation\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(accuracy, label=\"Training\")\n",
        "        plt.plot(val_accuracy, label=\"Validation\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        \n",
        "        plt.suptitle(\"Fold-{}\".format(k))\n",
        "        plt.show()\n",
        "\n",
        "In \\[56\\]:\n",
        "\n",
        "    # Displaying the graph results\n",
        "\n",
        "    for history in histories:\n",
        "        display_kfold_result(history, (histories.index(history)+1))\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/606a8f78abffb6d2f9520ae77764866ec986197a.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/a0f29ca1ba1c4d17ea4899270359594094e7ec60.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/4dc831bc683352ab56fe30c75efc199e3e125194.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/4daaf2800731350aeca3121468f5d6cd4301f8d0.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/b56e1330c48affb84178ac0b927a5098018ad3a6.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "In \\[57\\]:\n",
        "\n",
        "    i = 0\n",
        "    float2 = \"{0:.2f}\"\n",
        "    for score in eval_scores:\n",
        "        percent = score * 100\n",
        "        print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n",
        "        i = i + 1\n",
        "\n",
        "    Fold-1: 88.65%\n",
        "    Fold-2: 88.46%\n",
        "    Fold-3: 88.68%\n",
        "    Fold-4: 88.02%\n",
        "    Fold-5: 88.34%\n",
        "\n",
        "## Trying SGD Optimizer<a href=\"#Trying-SGD-Optimizer\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[61\\]:\n",
        "\n",
        "    model_3 = lenet5(input_shape, tf.keras.optimizers.SGD(learning_rate=0.001))\n",
        "\n",
        "    Model: \"sequential_5\"\n",
        "    _________________________________________________________________\n",
        "    Layer (type)                 Output Shape              Param #   \n",
        "    =================================================================\n",
        "    conv2d_10 (Conv2D)           (None, 24, 24, 6)         156       \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_10 (Averag (None, 12, 12, 6)         0         \n",
        "    _________________________________________________________________\n",
        "    conv2d_11 (Conv2D)           (None, 8, 8, 16)          2416      \n",
        "    _________________________________________________________________\n",
        "    average_pooling2d_11 (Averag (None, 4, 4, 16)          0         \n",
        "    _________________________________________________________________\n",
        "    flatten_5 (Flatten)          (None, 256)               0         \n",
        "    _________________________________________________________________\n",
        "    dense_15 (Dense)             (None, 120)               30840     \n",
        "    _________________________________________________________________\n",
        "    dense_16 (Dense)             (None, 84)                10164     \n",
        "    _________________________________________________________________\n",
        "    dense_17 (Dense)             (None, 10)                850       \n",
        "    =================================================================\n",
        "    Total params: 44,426\n",
        "    Trainable params: 44,426\n",
        "    Non-trainable params: 0\n",
        "    _________________________________________________________________\n",
        "\n",
        "In \\[62\\]:\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    k = 5\n",
        "    cross_val = KFold(k, shuffle=True, random_state=1)\n",
        "    fold_count = 1\n",
        "\n",
        "    # For training epochs\n",
        "    epochs = 32\n",
        "\n",
        "    # For loss & acc plotting\n",
        "    histories = []\n",
        "\n",
        "    # For testing/evaluation acc scores\n",
        "    eval_scores = []\n",
        "\n",
        "    # For callbacks\n",
        "    es_callbacks = EarlyStopping(monitor=\"val_loss\",\n",
        "                                              mode=\"min\",\n",
        "                                              verbose=1,\n",
        "                                              patience=4)\n",
        "\n",
        "In \\[63\\]:\n",
        "\n",
        "    for train, validation in cross_val.split(X_train):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Fold-{}\".format(fold_count))\n",
        "        print(\"-\"*80)\n",
        "        print(\"Training & Validation\")\n",
        "        fold_count = fold_count + 1\n",
        "        \n",
        "        \n",
        "        X_train_, y_train_ = X_train[train], y_train[train]\n",
        "        X_val, y_val = X_train[validation], y_train[validation]\n",
        "        \n",
        "        history = model_3.fit(X_train_, y_train_,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[es_callbacks])\n",
        "        \n",
        "        print(\"-\"*80)\n",
        "        print(\"Testing/evaluation\")\n",
        "        eval_loss, eval_accuracy = model_3.evaluate(X_test, y_test)\n",
        "        \n",
        "        histories.append(history)\n",
        "        eval_scores.append(eval_accuracy)\n",
        "        print(\"_\"*80)\n",
        "\n",
        "    ================================================================================\n",
        "    Fold-1\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 1.8003 - accuracy: 0.4500 - val_loss: 1.3186 - val_accuracy: 0.6237\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 1.1062 - accuracy: 0.6729 - val_loss: 0.9928 - val_accuracy: 0.6818\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.9144 - accuracy: 0.7028 - val_loss: 0.8777 - val_accuracy: 0.6963\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.8241 - accuracy: 0.7171 - val_loss: 0.8088 - val_accuracy: 0.7146\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.7665 - accuracy: 0.7286 - val_loss: 0.7633 - val_accuracy: 0.7233\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.7264 - accuracy: 0.7363 - val_loss: 0.7299 - val_accuracy: 0.7279\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.6970 - accuracy: 0.7435 - val_loss: 0.7070 - val_accuracy: 0.7351\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.6743 - accuracy: 0.7499 - val_loss: 0.6858 - val_accuracy: 0.7401\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.6559 - accuracy: 0.7559 - val_loss: 0.6693 - val_accuracy: 0.7477\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.6402 - accuracy: 0.7606 - val_loss: 0.6557 - val_accuracy: 0.7524\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.6265 - accuracy: 0.7659 - val_loss: 0.6426 - val_accuracy: 0.7566\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.6145 - accuracy: 0.7704 - val_loss: 0.6314 - val_accuracy: 0.7595\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.6036 - accuracy: 0.7755 - val_loss: 0.6211 - val_accuracy: 0.7658\n",
        "    Epoch 14/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5939 - accuracy: 0.7794 - val_loss: 0.6113 - val_accuracy: 0.7700\n",
        "    Epoch 15/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5848 - accuracy: 0.7831 - val_loss: 0.6022 - val_accuracy: 0.7727\n",
        "    Epoch 16/32\n",
        "    1499/1499 [==============================] - 11s 7ms/step - loss: 0.5765 - accuracy: 0.7867 - val_loss: 0.5948 - val_accuracy: 0.7727\n",
        "    Epoch 17/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5688 - accuracy: 0.7900 - val_loss: 0.5873 - val_accuracy: 0.7770\n",
        "    Epoch 18/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5616 - accuracy: 0.7923 - val_loss: 0.5804 - val_accuracy: 0.7821\n",
        "    Epoch 19/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5550 - accuracy: 0.7947 - val_loss: 0.5739 - val_accuracy: 0.7839\n",
        "    Epoch 20/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5487 - accuracy: 0.7976 - val_loss: 0.5668 - val_accuracy: 0.7879\n",
        "    Epoch 21/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5427 - accuracy: 0.8012 - val_loss: 0.5627 - val_accuracy: 0.7882\n",
        "    Epoch 22/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5370 - accuracy: 0.8036 - val_loss: 0.5559 - val_accuracy: 0.7891\n",
        "    Epoch 23/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5320 - accuracy: 0.8052 - val_loss: 0.5500 - val_accuracy: 0.7924\n",
        "    Epoch 24/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.5268 - accuracy: 0.8070 - val_loss: 0.5454 - val_accuracy: 0.7919\n",
        "    Epoch 25/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.5222 - accuracy: 0.8089 - val_loss: 0.5413 - val_accuracy: 0.7996\n",
        "    Epoch 26/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.5172 - accuracy: 0.8117 - val_loss: 0.5354 - val_accuracy: 0.7994\n",
        "    Epoch 27/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5131 - accuracy: 0.8135 - val_loss: 0.5320 - val_accuracy: 0.8022\n",
        "    Epoch 28/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5088 - accuracy: 0.8141 - val_loss: 0.5263 - val_accuracy: 0.8040\n",
        "    Epoch 29/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.5047 - accuracy: 0.8164 - val_loss: 0.5216 - val_accuracy: 0.8058\n",
        "    Epoch 30/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.5005 - accuracy: 0.8182 - val_loss: 0.5183 - val_accuracy: 0.8077\n",
        "    Epoch 31/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4966 - accuracy: 0.8207 - val_loss: 0.5143 - val_accuracy: 0.8078\n",
        "    Epoch 32/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4931 - accuracy: 0.8219 - val_loss: 0.5098 - val_accuracy: 0.8105\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.8223\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-2\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4922 - accuracy: 0.8213 - val_loss: 0.4950 - val_accuracy: 0.8230\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4883 - accuracy: 0.8230 - val_loss: 0.4917 - val_accuracy: 0.8240\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4846 - accuracy: 0.8244 - val_loss: 0.4907 - val_accuracy: 0.8230\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4810 - accuracy: 0.8251 - val_loss: 0.4865 - val_accuracy: 0.8271\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4775 - accuracy: 0.8271 - val_loss: 0.4841 - val_accuracy: 0.8280\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4743 - accuracy: 0.8285 - val_loss: 0.4808 - val_accuracy: 0.8290\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4709 - accuracy: 0.8300 - val_loss: 0.4775 - val_accuracy: 0.8295\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4679 - accuracy: 0.8307 - val_loss: 0.4744 - val_accuracy: 0.8296\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4647 - accuracy: 0.8321 - val_loss: 0.4729 - val_accuracy: 0.8317\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4616 - accuracy: 0.8336 - val_loss: 0.4694 - val_accuracy: 0.8336\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4586 - accuracy: 0.8339 - val_loss: 0.4706 - val_accuracy: 0.8311\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4559 - accuracy: 0.8358 - val_loss: 0.4646 - val_accuracy: 0.8344\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4533 - accuracy: 0.8365 - val_loss: 0.4628 - val_accuracy: 0.8336\n",
        "    Epoch 14/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4506 - accuracy: 0.8384 - val_loss: 0.4605 - val_accuracy: 0.8357\n",
        "    Epoch 15/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4480 - accuracy: 0.8385 - val_loss: 0.4570 - val_accuracy: 0.8381\n",
        "    Epoch 16/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4453 - accuracy: 0.8400 - val_loss: 0.4552 - val_accuracy: 0.8385\n",
        "    Epoch 17/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4428 - accuracy: 0.8406 - val_loss: 0.4541 - val_accuracy: 0.8372\n",
        "    Epoch 18/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4405 - accuracy: 0.8417 - val_loss: 0.4524 - val_accuracy: 0.8383\n",
        "    Epoch 19/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4382 - accuracy: 0.8426 - val_loss: 0.4499 - val_accuracy: 0.8397\n",
        "    Epoch 20/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4360 - accuracy: 0.8427 - val_loss: 0.4480 - val_accuracy: 0.8421\n",
        "    Epoch 21/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4336 - accuracy: 0.8447 - val_loss: 0.4445 - val_accuracy: 0.8421\n",
        "    Epoch 22/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4315 - accuracy: 0.8445 - val_loss: 0.4446 - val_accuracy: 0.8412\n",
        "    Epoch 23/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4294 - accuracy: 0.8466 - val_loss: 0.4409 - val_accuracy: 0.8444\n",
        "    Epoch 24/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4274 - accuracy: 0.8463 - val_loss: 0.4407 - val_accuracy: 0.8438\n",
        "    Epoch 25/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4254 - accuracy: 0.8470 - val_loss: 0.4380 - val_accuracy: 0.8454\n",
        "    Epoch 26/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4235 - accuracy: 0.8486 - val_loss: 0.4364 - val_accuracy: 0.8452\n",
        "    Epoch 27/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4217 - accuracy: 0.8482 - val_loss: 0.4347 - val_accuracy: 0.8455\n",
        "    Epoch 28/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4197 - accuracy: 0.8486 - val_loss: 0.4333 - val_accuracy: 0.8469\n",
        "    Epoch 29/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4178 - accuracy: 0.8491 - val_loss: 0.4310 - val_accuracy: 0.8481\n",
        "    Epoch 30/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4162 - accuracy: 0.8500 - val_loss: 0.4306 - val_accuracy: 0.8475\n",
        "    Epoch 31/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4143 - accuracy: 0.8502 - val_loss: 0.4276 - val_accuracy: 0.8489\n",
        "    Epoch 32/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4125 - accuracy: 0.8516 - val_loss: 0.4265 - val_accuracy: 0.8490\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.4152 - accuracy: 0.8553\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-3\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4165 - accuracy: 0.8501 - val_loss: 0.4020 - val_accuracy: 0.8576\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4145 - accuracy: 0.8507 - val_loss: 0.4025 - val_accuracy: 0.8566\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4129 - accuracy: 0.8505 - val_loss: 0.4001 - val_accuracy: 0.8591\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4111 - accuracy: 0.8509 - val_loss: 0.3991 - val_accuracy: 0.8584\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4094 - accuracy: 0.8519 - val_loss: 0.3976 - val_accuracy: 0.8601\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4078 - accuracy: 0.8528 - val_loss: 0.3962 - val_accuracy: 0.8606\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.4061 - accuracy: 0.8532 - val_loss: 0.3957 - val_accuracy: 0.8606\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4047 - accuracy: 0.8538 - val_loss: 0.3941 - val_accuracy: 0.8605\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4032 - accuracy: 0.8550 - val_loss: 0.3933 - val_accuracy: 0.8611\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.4017 - accuracy: 0.8555 - val_loss: 0.3937 - val_accuracy: 0.8604\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.4003 - accuracy: 0.8556 - val_loss: 0.3916 - val_accuracy: 0.8611\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3986 - accuracy: 0.8556 - val_loss: 0.3906 - val_accuracy: 0.8610\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3976 - accuracy: 0.8563 - val_loss: 0.3894 - val_accuracy: 0.8626\n",
        "    Epoch 14/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3959 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8621\n",
        "    Epoch 15/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3945 - accuracy: 0.8570 - val_loss: 0.3880 - val_accuracy: 0.8618\n",
        "    Epoch 16/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3933 - accuracy: 0.8580 - val_loss: 0.3865 - val_accuracy: 0.8642\n",
        "    Epoch 17/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3919 - accuracy: 0.8584 - val_loss: 0.3851 - val_accuracy: 0.8646\n",
        "    Epoch 18/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3906 - accuracy: 0.8588 - val_loss: 0.3837 - val_accuracy: 0.8649\n",
        "    Epoch 19/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3891 - accuracy: 0.8592 - val_loss: 0.3836 - val_accuracy: 0.8636\n",
        "    Epoch 20/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3878 - accuracy: 0.8593 - val_loss: 0.3831 - val_accuracy: 0.8650\n",
        "    Epoch 21/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3865 - accuracy: 0.8607 - val_loss: 0.3826 - val_accuracy: 0.8649\n",
        "    Epoch 22/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3854 - accuracy: 0.8605 - val_loss: 0.3801 - val_accuracy: 0.8664\n",
        "    Epoch 23/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3842 - accuracy: 0.8611 - val_loss: 0.3800 - val_accuracy: 0.8664\n",
        "    Epoch 24/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3829 - accuracy: 0.8613 - val_loss: 0.3777 - val_accuracy: 0.8673\n",
        "    Epoch 25/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3818 - accuracy: 0.8615 - val_loss: 0.3774 - val_accuracy: 0.8679\n",
        "    Epoch 26/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3807 - accuracy: 0.8625 - val_loss: 0.3774 - val_accuracy: 0.8664\n",
        "    Epoch 27/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3794 - accuracy: 0.8625 - val_loss: 0.3783 - val_accuracy: 0.8653\n",
        "    Epoch 28/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3782 - accuracy: 0.8631 - val_loss: 0.3761 - val_accuracy: 0.8688\n",
        "    Epoch 29/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3772 - accuracy: 0.8638 - val_loss: 0.3751 - val_accuracy: 0.8647\n",
        "    Epoch 30/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3760 - accuracy: 0.8641 - val_loss: 0.3734 - val_accuracy: 0.8687\n",
        "    Epoch 31/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3750 - accuracy: 0.8640 - val_loss: 0.3723 - val_accuracy: 0.8693\n",
        "    Epoch 32/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3738 - accuracy: 0.8648 - val_loss: 0.3716 - val_accuracy: 0.8694\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8640\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-4\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3757 - accuracy: 0.8665 - val_loss: 0.3585 - val_accuracy: 0.8674\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3744 - accuracy: 0.8666 - val_loss: 0.3590 - val_accuracy: 0.8670\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3732 - accuracy: 0.8670 - val_loss: 0.3581 - val_accuracy: 0.8681\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3721 - accuracy: 0.8674 - val_loss: 0.3593 - val_accuracy: 0.8660\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3712 - accuracy: 0.8672 - val_loss: 0.3562 - val_accuracy: 0.8682\n",
        "    Epoch 6/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3699 - accuracy: 0.8682 - val_loss: 0.3564 - val_accuracy: 0.8680\n",
        "    Epoch 7/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3690 - accuracy: 0.8678 - val_loss: 0.3566 - val_accuracy: 0.8697\n",
        "    Epoch 8/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3677 - accuracy: 0.8688 - val_loss: 0.3566 - val_accuracy: 0.8674\n",
        "    Epoch 9/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3670 - accuracy: 0.8691 - val_loss: 0.3545 - val_accuracy: 0.8682\n",
        "    Epoch 10/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3658 - accuracy: 0.8691 - val_loss: 0.3538 - val_accuracy: 0.8692\n",
        "    Epoch 11/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3645 - accuracy: 0.8701 - val_loss: 0.3527 - val_accuracy: 0.8696\n",
        "    Epoch 12/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3638 - accuracy: 0.8700 - val_loss: 0.3518 - val_accuracy: 0.8695\n",
        "    Epoch 13/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3626 - accuracy: 0.8706 - val_loss: 0.3517 - val_accuracy: 0.8696\n",
        "    Epoch 14/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3619 - accuracy: 0.8707 - val_loss: 0.3517 - val_accuracy: 0.8687\n",
        "    Epoch 15/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3607 - accuracy: 0.8717 - val_loss: 0.3530 - val_accuracy: 0.8680\n",
        "    Epoch 16/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3600 - accuracy: 0.8712 - val_loss: 0.3492 - val_accuracy: 0.8727\n",
        "    Epoch 17/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3589 - accuracy: 0.8715 - val_loss: 0.3482 - val_accuracy: 0.8702\n",
        "    Epoch 18/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3578 - accuracy: 0.8715 - val_loss: 0.3488 - val_accuracy: 0.8708\n",
        "    Epoch 19/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3570 - accuracy: 0.8724 - val_loss: 0.3484 - val_accuracy: 0.8707\n",
        "    Epoch 20/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3561 - accuracy: 0.8731 - val_loss: 0.3463 - val_accuracy: 0.8712\n",
        "    Epoch 21/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3552 - accuracy: 0.8725 - val_loss: 0.3474 - val_accuracy: 0.8720\n",
        "    Epoch 22/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3541 - accuracy: 0.8738 - val_loss: 0.3459 - val_accuracy: 0.8720\n",
        "    Epoch 23/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3535 - accuracy: 0.8742 - val_loss: 0.3445 - val_accuracy: 0.8720\n",
        "    Epoch 24/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3525 - accuracy: 0.8744 - val_loss: 0.3449 - val_accuracy: 0.8702\n",
        "    Epoch 25/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3515 - accuracy: 0.8738 - val_loss: 0.3448 - val_accuracy: 0.8714\n",
        "    Epoch 26/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3509 - accuracy: 0.8745 - val_loss: 0.3428 - val_accuracy: 0.8727\n",
        "    Epoch 27/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3499 - accuracy: 0.8755 - val_loss: 0.3427 - val_accuracy: 0.8735\n",
        "    Epoch 28/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3487 - accuracy: 0.8764 - val_loss: 0.3438 - val_accuracy: 0.8730\n",
        "    Epoch 29/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3479 - accuracy: 0.8766 - val_loss: 0.3421 - val_accuracy: 0.8729\n",
        "    Epoch 30/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3471 - accuracy: 0.8760 - val_loss: 0.3405 - val_accuracy: 0.8743\n",
        "    Epoch 31/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3464 - accuracy: 0.8767 - val_loss: 0.3399 - val_accuracy: 0.8736\n",
        "    Epoch 32/32\n",
        "    1499/1499 [==============================] - 9s 6ms/step - loss: 0.3456 - accuracy: 0.8773 - val_loss: 0.3388 - val_accuracy: 0.8741\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8693\n",
        "    ________________________________________________________________________________\n",
        "    ================================================================================\n",
        "    Fold-5\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3430 - accuracy: 0.8768 - val_loss: 0.3456 - val_accuracy: 0.8782\n",
        "    Epoch 2/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3420 - accuracy: 0.8772 - val_loss: 0.3473 - val_accuracy: 0.8757\n",
        "    Epoch 3/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3410 - accuracy: 0.8777 - val_loss: 0.3469 - val_accuracy: 0.8766\n",
        "    Epoch 4/32\n",
        "    1499/1499 [==============================] - 10s 6ms/step - loss: 0.3401 - accuracy: 0.8776 - val_loss: 0.3473 - val_accuracy: 0.8754\n",
        "    Epoch 5/32\n",
        "    1499/1499 [==============================] - 10s 7ms/step - loss: 0.3391 - accuracy: 0.8784 - val_loss: 0.3456 - val_accuracy: 0.8776\n",
        "    Epoch 00005: early stopping\n",
        "    --------------------------------------------------------------------------------\n",
        "    Testing/evaluation\n",
        "    313/313 [==============================] - 1s 3ms/step - loss: 0.3524 - accuracy: 0.8696\n",
        "    ________________________________________________________________________________\n",
        "\n",
        "In \\[64\\]:\n",
        "\n",
        "    def display_kfold_result(history, k=1):\n",
        "        # Train & Val Loss\n",
        "        loss = history.history[\"loss\"]\n",
        "        val_loss = history.history[\"val_loss\"]\n",
        "        \n",
        "        # Train & Val Accuracy\n",
        "        accuracy = history.history[\"accuracy\"]\n",
        "        val_accuracy = history.history[\"val_accuracy\"]\n",
        "        \n",
        "        plt.figure(figsize=(15, 5))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(loss, label=\"Training\")\n",
        "        plt.plot(val_loss, label=\"Validation\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(accuracy, label=\"Training\")\n",
        "        plt.plot(val_accuracy, label=\"Validation\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        \n",
        "        plt.suptitle(\"Fold-{}\".format(k))\n",
        "        plt.show()\n",
        "\n",
        "In \\[65\\]:\n",
        "\n",
        "    # Displaying the graph results\n",
        "\n",
        "    for history in histories:\n",
        "        display_kfold_result(history, (histories.index(history)+1))\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/51cdbbcbafcd3f40bb2e3ffeec2a99c816751142.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/3628fb97a2ed600f8952f6954dc1e6c038f1dfd1.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/4f95a22e0b22ce35841c79756f50a767d4241009.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/d4ff03591c62e6f6487bde3898678f841f583b93.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/53093ad823a0a63e07321a0b1ddf0ad8950056c2.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "In \\[66\\]:\n",
        "\n",
        "    i = 0\n",
        "    float2 = \"{0:.2f}\"\n",
        "    for score in eval_scores:\n",
        "        percent = score * 100\n",
        "        print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n",
        "        i = i + 1\n",
        "\n",
        "    Fold-1: 82.23%\n",
        "    Fold-2: 85.53%\n",
        "    Fold-3: 86.40%\n",
        "    Fold-4: 86.93%\n",
        "    Fold-5: 86.96%\n",
        "\n",
        "# Transfer Learning<a href=\"#Transfer-Learning\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "## Trying to use another 2 different CNNs models to compare the results with LeNet5-5<a href=\"#Trying-to-use-another-2-different-CNNs-models-to-compare-the-results-with-LeNet5-5\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "### Implementing functions for resizing the images and making it with 3 channels to be suitable with the other models<a href=\"#Implementing-functions-for-resizing-the-images-and-making-it-with-3-channels-to-be-suitable-with-the-other-models\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[67\\]:\n",
        "\n",
        "    import cv2\n",
        "    def to_3_channels(X_1):\n",
        "        X_3 = np.empty([X_1.shape[0], X_1.shape[1], X_1.shape[2], 3], dtype=float)\n",
        "\n",
        "        for i in range(X_1.shape[0]):\n",
        "            X_3[i] = cv2.merge([X_1[i],X_1[i],X_1[i]])\n",
        "            \n",
        "        return X_3\n",
        "\n",
        "In \\[68\\]:\n",
        "\n",
        "    def resize_image(X_3, x_size, y_size):\n",
        "        X_3_resized = np.empty([X_3.shape[0], x_size, y_size, 3], dtype=float)\n",
        "\n",
        "        for i in range(X_3.shape[0]):\n",
        "            X_3_resized[i] = tf.image.resize(X_3[i], (x_size, y_size))\n",
        "            \n",
        "        return X_3_resized\n",
        "\n",
        "### Transforming Images<a href=\"#Transforming-Images\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[69\\]:\n",
        "\n",
        "    X_train_3_32 = resize_image(to_3_channels(X_train), 32, 32)\n",
        "    X_test_3_32 = resize_image(to_3_channels(X_test), 32, 32)\n",
        "\n",
        "In \\[70\\]:\n",
        "\n",
        "    print(X_train_3_32.shape, X_train.shape)\n",
        "    print(X_test_3_32.shape, X_test.shape)\n",
        "\n",
        "    (59957, 32, 32, 3) (59957, 28, 28, 1)\n",
        "    (10000, 32, 32, 3) (10000, 28, 28, 1)\n",
        "\n",
        "In \\[71\\]:\n",
        "\n",
        "    print(X_train.shape, to_3_channels(X_train).shape)\n",
        "    print(type(X_train), type(to_3_channels(X_train)))\n",
        "    print(X_train[0][0][0], to_3_channels(X_train)[0][0][0], to_3_channels(X_train)[0][0][0][0])\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(256*X_train[1], cmap='gray', vmin=0, vmax=255)\n",
        "    #plt.legend(loc=\"left\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(X_train_3_32[1], cmap='brg', vmin=0, vmax=255)\n",
        "    #plt.legend(loc=\"right\")\n",
        "    plt.show()\n",
        "\n",
        "    (59957, 28, 28, 1) (59957, 28, 28, 3)\n",
        "    <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
        "    [0.] [0. 0. 0.] 0.0\n",
        "\n",
        "<img src=\"attachment:vertopal_f27c1d22bea84e3a859cbade3859e04e/9e91d07bcf13dc12d4d38f65988894b24ac22a9e.png\" class=\"jp-needs-light-background\" />\n",
        "\n",
        "## Trying with VGG16<a href=\"#Trying-with-VGG16\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[74\\]:\n",
        "\n",
        "    from keras.models import Model\n",
        "\n",
        "In \\[77\\]:\n",
        "\n",
        "    from keras.applications.vgg16 import VGG16\n",
        "    from keras.layers import Dense, Flatten\n",
        "\n",
        "    model_VGG16 = VGG16(include_top=False, input_shape=(32,32,3), weights='imagenet')\n",
        "\n",
        "    # Freeze all the layers\n",
        "    for layer in model_VGG16.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add Dense layer as in VGG16\n",
        "    output = model_VGG16.output\n",
        "    output = Flatten()(output)\n",
        "    output = Dense(units=100, activation='relu')(output)\n",
        "    output = Dense(units=10, activation='softmax')(output)\n",
        "    model_VGG16 = Model(model_VGG16.input, output)\n",
        "    model_VGG16.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "    model_VGG16.summary()\n",
        "\n",
        "    Model: \"model_2\"\n",
        "    _________________________________________________________________\n",
        "    Layer (type)                 Output Shape              Param #   \n",
        "    =================================================================\n",
        "    input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
        "    _________________________________________________________________\n",
        "    block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
        "    _________________________________________________________________\n",
        "    block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
        "    _________________________________________________________________\n",
        "    block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
        "    _________________________________________________________________\n",
        "    block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
        "    _________________________________________________________________\n",
        "    block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
        "    _________________________________________________________________\n",
        "    block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
        "    _________________________________________________________________\n",
        "    block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
        "    _________________________________________________________________\n",
        "    block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
        "    _________________________________________________________________\n",
        "    block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
        "    _________________________________________________________________\n",
        "    block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
        "    _________________________________________________________________\n",
        "    block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
        "    _________________________________________________________________\n",
        "    block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
        "    _________________________________________________________________\n",
        "    block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
        "    _________________________________________________________________\n",
        "    block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
        "    _________________________________________________________________\n",
        "    block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
        "    _________________________________________________________________\n",
        "    block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
        "    _________________________________________________________________\n",
        "    block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
        "    _________________________________________________________________\n",
        "    block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
        "    _________________________________________________________________\n",
        "    flatten_9 (Flatten)          (None, 512)               0         \n",
        "    _________________________________________________________________\n",
        "    dense_24 (Dense)             (None, 100)               51300     \n",
        "    _________________________________________________________________\n",
        "    dense_25 (Dense)             (None, 10)                1010      \n",
        "    =================================================================\n",
        "    Total params: 14,766,998\n",
        "    Trainable params: 52,310\n",
        "    Non-trainable params: 14,714,688\n",
        "    _________________________________________________________________\n",
        "\n",
        "In \\[78\\]:\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    k = 5\n",
        "    cross_val = KFold(k, shuffle=True, random_state=1)\n",
        "    fold_count = 1\n",
        "\n",
        "    # For training epochs\n",
        "    epochs = 15\n",
        "\n",
        "    # For loss & acc plotting\n",
        "    histories = []\n",
        "\n",
        "    # For testing/evaluation acc scores\n",
        "    eval_scores = []\n",
        "\n",
        "    # For callbacks\n",
        "    es_callbacks = EarlyStopping(monitor=\"val_loss\",\n",
        "                                              mode=\"min\",\n",
        "                                              verbose=1,\n",
        "                                              patience=4)\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    for train, validation in cross_val.split(X_train):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Fold-{}\".format(fold_count))\n",
        "        print(\"-\"*80)\n",
        "        print(\"Training & Validation\")\n",
        "        fold_count = fold_count + 1\n",
        "        \n",
        "        \n",
        "        X_train_, y_train_ = X_train_3_32[train], y_train[train]\n",
        "        X_val, y_val = X_train_3_32[validation], y_train[validation]\n",
        "        \n",
        "        history = model_VGG16.fit(X_train_, y_train_,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[es_callbacks])\n",
        "        \n",
        "        print(\"-\"*80)\n",
        "        print(\"Testing/evaluation\")\n",
        "        eval_loss, eval_accuracy = model_VGG16.evaluate(X_test_3_32, y_test)\n",
        "        \n",
        "        histories.append(history)\n",
        "        eval_scores.append(eval_accuracy)\n",
        "        print(\"_\"*80)\n",
        "\n",
        "    ================================================================================\n",
        "    Fold-1\n",
        "    --------------------------------------------------------------------------------\n",
        "    Training & Validation\n",
        "    Epoch 1/15\n",
        "     283/1499 [====>.........................] - ETA: 4:17 - loss: 0.8759 - accuracy: 0.7151\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    def display_kfold_result(history, k=1):\n",
        "        # Train & Val Loss\n",
        "        loss = history.history[\"loss\"]\n",
        "        val_loss = history.history[\"val_loss\"]\n",
        "        \n",
        "        # Train & Val Accuracy\n",
        "        accuracy = history.history[\"accuracy\"]\n",
        "        val_accuracy = history.history[\"val_accuracy\"]\n",
        "        \n",
        "        plt.figure(figsize=(15, 5))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(loss, label=\"Training\")\n",
        "        plt.plot(val_loss, label=\"Validation\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(accuracy, label=\"Training\")\n",
        "        plt.plot(val_accuracy, label=\"Validation\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        \n",
        "        plt.suptitle(\"Fold-{}\".format(k))\n",
        "        plt.show()\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    # Displaying the graph results\n",
        "\n",
        "    for history in histories:\n",
        "        display_kfold_result(history, (histories.index(history)+1))\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    i = 0\n",
        "    float2 = \"{0:.2f}\"\n",
        "    for score in eval_scores:\n",
        "        percent = score * 100\n",
        "        print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n",
        "        i = i + 1\n",
        "\n",
        "## Trying with ResNet50<a href=\"#Trying-with-ResNet50\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    from keras.models import Model\n",
        "    from keras.layers import Dense, GlobalAveragePooling2D\n",
        "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "    model_RESNET = ResNet50(include_top=False, input_shape=(32,32,3), weights='imagenet')\n",
        "\n",
        "    # Freeze all the layers\n",
        "    for layer in model_RESNET.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add Dense layer to classify on CIFAR10\n",
        "    output = model_RESNET.output\n",
        "    output = GlobalAveragePooling2D()(output)\n",
        "    output = Dense(units=10, activation='softmax')(output)\n",
        "    model_RESNET = Model(model_RESNET.input, output)\n",
        "    model_RESNET.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "    model_RESNET.summary()\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    visualkeras.layered_view(model_RESNET)\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    k = 5\n",
        "    cross_val = KFold(k, shuffle=True, random_state=1)\n",
        "    fold_count = 1\n",
        "\n",
        "    # For training epochs\n",
        "    epochs = 15\n",
        "\n",
        "    # For loss & acc plotting\n",
        "    histories = []\n",
        "\n",
        "    # For testing/evaluation acc scores\n",
        "    eval_scores = []\n",
        "\n",
        "    # For callbacks\n",
        "    es_callbacks = EarlyStopping(monitor=\"val_loss\",\n",
        "                                              mode=\"min\",\n",
        "                                              verbose=1,\n",
        "                                              patience=4)\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    for train, validation in cross_val.split(X_train):\n",
        "        print(\"=\"*80)\n",
        "        print(\"Fold-{}\".format(fold_count))\n",
        "        print(\"-\"*80)\n",
        "        print(\"Training & Validation\")\n",
        "        fold_count = fold_count + 1\n",
        "        \n",
        "        \n",
        "        X_train_, y_train_ = X_train_3_32[train], y_train[train]\n",
        "        X_val, y_val = X_train_3_32[validation], y_train[validation]\n",
        "        \n",
        "        history = model_RESNET.fit(X_train_, y_train_,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[es_callbacks])\n",
        "        \n",
        "        print(\"-\"*80)\n",
        "        print(\"Testing/evaluation\")\n",
        "        eval_loss, eval_accuracy = model_RESNET.evaluate(X_test_3_32, y_test)\n",
        "        \n",
        "        histories.append(history)\n",
        "        eval_scores.append(eval_accuracy)\n",
        "        print(\"_\"*80)\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    def display_kfold_result(history, k=1):\n",
        "        # Train & Val Loss\n",
        "        loss = history.history[\"loss\"]\n",
        "        val_loss = history.history[\"val_loss\"]\n",
        "        \n",
        "        # Train & Val Accuracy\n",
        "        accuracy = history.history[\"accuracy\"]\n",
        "        val_accuracy = history.history[\"val_accuracy\"]\n",
        "        \n",
        "        plt.figure(figsize=(15, 5))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Loss\")\n",
        "        plt.plot(loss, label=\"Training\")\n",
        "        plt.plot(val_loss, label=\"Validation\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Accuracy\")\n",
        "        plt.plot(accuracy, label=\"Training\")\n",
        "        plt.plot(val_accuracy, label=\"Validation\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        \n",
        "        plt.suptitle(\"Fold-{}\".format(k))\n",
        "        plt.show()\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    # Displaying the graph results\n",
        "\n",
        "    for history in histories:\n",
        "        display_kfold_result(history, (histories.index(history)+1))\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "    i = 0\n",
        "    float2 = \"{0:.2f}\"\n",
        "    for score in eval_scores:\n",
        "        percent = score * 100\n",
        "        print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n",
        "        i = i + 1\n",
        "\n",
        "## Comparing the Results of the 3 Models<a href=\"#Comparing-the-Results-of-the-3-Models\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "In \\[ \\]:\n",
        "\n",
        "     \n",
        "\n",
        "## Comment on why you think LeNet-5 further improves the accuracy if any at all. And if it doesn't, why not?<a href=\"#Comment-on-why-you-think-LeNet-5-further-improves-the-accuracy-if-any-at-all.-And-if-it-doesn&#39;t,-why-not?\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "### The architecture was designed to identify handwritten digits in the MNIST data-set and wasn't intended for image recognition but still in our case it out performs the other models several probable reasons<a href=\"#The-architecture-was-designed-to-identify-handwritten-digits-in-the-MNIST-data-set-and-wasn&#39;t-intended-for-image-recognition-but-still-in-our-case-it-out-performs-the-other-models-several-probable-reasons\" class=\"anchor-link\">¶</a>\n",
        "\n",
        "-   We did the hyperparameter tuning and the k-fold evaluation to\n",
        "    achieve the very best performance we can get, which won't be\n",
        "    feasible on the other complicated CNNs we used.\n",
        "-   We used a smaller batch size and a larger number of epochs since the\n",
        "    architecture is quite easier and simpler and way faster than the\n",
        "    other complicated CNNs we used.\n",
        "-   The LeNet is originally intended for grayscale images so it gives a\n",
        "    somewhat descent performance, while both ResNet50 & VGG16 are\n",
        "    intended for rgb images and also the images needed to be rescaled\n",
        "    which is done crudely and that affected the perfrmance"
      ],
      "id": "YTly760raXeB"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    }
  }
}